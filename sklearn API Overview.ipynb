{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is very far from exhaustive, but a collection of things I have found useful over time.\n",
      "\n",
      "###Loading Data\n",
      "\n",
      "- If the data is a csv file and only contains numerical values, numpy.loadtxt is very convenient.\n",
      "- If the data is more complicated, the builtin python csv module is often useful."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "X_train = np.loadtxt('data/pie_train_data.txt', delimiter=',')\n",
      "y_train = np.loadtxt('data/pie_train_label.txt', delimiter=',')\n",
      "X_test = np.loadtxt('data/pie_test_data.txt', delimiter=',')\n",
      "y_test = np.loadtxt('data/pie_test_label.txt', delimiter=',')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "reader = csv.reader(open('data/pie_train_data.txt'))\n",
      "for row in reader:\n",
      "    pass # do something with the data here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Fitting a model\n",
      "1. Import (load) the model\n",
      "2. Create an instance of the model\n",
      "3. Call the fit method with training data and training targets as arguments"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.lda import LDA\n",
      "lda = LDA()\n",
      "lda.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Making Predictions\n",
      "- Call the predict method of your fitted model with the test data as argument and assign it to a new variable"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_test_predict = lda.predict(Xt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Scoring a Prediction\n",
      "\n",
      "For this you need to have the targets. Note If you're making real world predictions you generally won't have access to these and that's precisely why you're making predictions.\n",
      "\n",
      "1. Import a scoring function\n",
      "2. Call it with the true target values and the predicted target values as arguments"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import accuracy_score\n",
      "accuracy_score(y_test_predict, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Binarizing Labels\n",
      "\n",
      "Data often has catogorical attributes. Say a color could be 'red', 'green' or 'blue'. If we simply convert these to numbers, say 1, 2 or 3. And feed it directly to an algorithm we are implictly making the assumption that 'green' is closer to 'blue' than 'red' is to 'blue'. To avoid this we need to binarize the labels.\n",
      "\n",
      "This means we create three new binary attributes that we could call 'is_red', 'is_green', and 'is_blue'.\n",
      "\n",
      "1. Import LabelBinarizer\n",
      "2. Create LabelBinarizer instance\n",
      "3. Fit instance\n",
      "4. Transform data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import LabelBinarizer\n",
      "toy_data = ['red', 'green', 'blue', 'blue', 'green']\n",
      "label_binarizer = LabelBinarizer()\n",
      "label_binarizer.fit(toy_data)\n",
      "label_binarizer.transform(toy_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Estimating a Model's Performance\n",
      "\n",
      "In real world application we want to predict unknown target values of some input data, but we would also like to get an idea as to how our model is expected to perform. A very useful technique is called cross validation. We split the data up in a few folds (usually 5) and iteratively use one of the folds as (fake) test set and the other folds as training set.\n",
      "\n",
      "1. Create instance of the model of which we want to evaluate the performance\n",
      "2. Import cross_val_score\n",
      "3. Call cross_val_score with model instance and data as arguments\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score\n",
      "from sklearn.lda import LDA\n",
      "lda = LDA()\n",
      "cross_val_score(lda, X_train, y_train, cv=5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Performing a Grid Search for Parameters\n",
      "\n",
      "Some models have a few parameters that affect the performance in complicated ways. It's sometimes very difficult to guess suitable values for them. Sklearn has built in functionality to find suitable parameters with cross validation over a parameter grid.\n",
      "\n",
      "1. Import GridSearchCV\n",
      "2. Create an instance of the model to test\n",
      "3. Create a parameter grid to search over\n",
      "4. Create instance of GridSearchCV and pass the model and the parameter grid as arguments\n",
      "5. Fit the GridSearchCV instance with data\n",
      "6. Look at the performance and select the best set of parameters found"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.svm import SVC\n",
      "svc = SVC()\n",
      "param_grid = [\n",
      "  {'C': [1, 10, 100, 1000, 10000], 'gamma': [0.1, 0.01, 0.001, 0.0001], 'kernel': ['rbf']},\n",
      " ]\n",
      "grid_search_cv = GridSearchCV(svc, param_grid, verbose=1)\n",
      "grid_search_cv.fit(X_train, y_train)\n",
      "print \"Best parameters, {}\\n\".format(grid_search_cv.best_params_)\n",
      "print \"Best score, {}\\n\".format(grid_search_cv.best_score_)\n",
      "print \"Best estimator, {}\\n\".format(grid_search_cv.best_estimator_)\n",
      "best_model = grid_search_cv.best_estimator_\n",
      "best_model.fit(X_train, y_train)\n",
      "y_test_predict = best_model.predict(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}